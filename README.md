# Talking-Head & Embodied-Avatar Research Timeline

**Purpose**  
A continuously updated chronology of research papers, open-source demos, and product releases that advance photorealistic human-animation technologies: voice-driven “talking heads,” volumetric avatars, depth-aware diffusion, and adjacent robotics or embodied-agent work.  
Although I am *not* an engineer, I track this space closely.

**Origins**  
The July 2024 **LivePortrait** demo sparked my curiosity about how quickly still-image animation was converging with full-body digital humans. This document began as personal notes.

**Scope**  
Core focus — face animation, lip-sync, depth/segmentation pipelines, image-to-3D, Gaussian-splat-based scene representation, audio-to-face, 3D Gaussian avatars, and related visual-speech synthesis.  
* Adjacent threads — convergence with embodied robotics vision, mulitimodality, and agent embodiment are welcome, though I maintain a separate robotics log separately at <https://ethanbholland.com/category/ai/robotics-embodiment/> and multimodality at <https://ethanbholland.com/category/ai/multimodal/>

**Using this timeline**  
Entries appear in **reverse chronological order** (newest first) under dated headings. Each line contains: **Title · link · brief one-liner**. Use your browser’s search to filter by keyword or year.

**Contributing**  
1. Open an **Issue** or **Pull Request** on GitHub.  
2. Add one line per item, formatted as above (date first, then title, then link).  
3. Keep commentary brief—this list is a high-signal reference, not a blog post.

**Acknowledgments**  
Gratitude to **Bilawal Sidhu** <https://www.linkedin.com/in/bilawalsidhu/> and **Jack Saunders** <https://www.linkedin.com/in/jack-r-saunders/> for inspiring this compilation and for their own exemplary curation work. Thanks to Alexandre Morgand <http://alexandremorgand.fr/> for suggesting I move my notes from a shared Google doc to GitHub. Additional commentary and related essays live at <https://ethanbholland.com/>.

**License**  
Content is released under **CC BY 4.0**. Reuse freely with attribution.

---
